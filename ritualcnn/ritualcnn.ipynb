{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4221d6b-2fc0-45e8-a7aa-e10de810ce60",
   "metadata": {},
   "source": [
    "## 0.1 - Import tensorflow and list GPU devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625f4426-a1a2-4080-9ac8-64313a08b53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Aucun GPU disponible\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "if gpus:\n",
    "    print(\"GPUs disponibles :\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"Aucun GPU disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe651b17-7151-45b7-a282-0140fecd61dc",
   "metadata": {},
   "source": [
    "## 0.2 - Every imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bac23e-846e-4c9d-a204-829aaa66fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tf2onnx\n",
    "import onnx\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, Reshape, LSTM, TimeDistributed, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers.legacy import Adam \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "import torch.onnx\n",
    "import random\n",
    "from PIL import ImageOps, ImageEnhance\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageOps, ImageEnhance, ImageChops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39058f4f-47b9-445e-9db3-58065dc06419",
   "metadata": {},
   "source": [
    "## 0.3 - Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f06189d-dfef-4e5f-88ed-e86f742bec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "input_shape = 128\n",
    "directory_path = './data'\n",
    "augmented_path = f\"{directory_path}_augment\"\n",
    "test_dir = \"test\"\n",
    "onnx_model_path = \"rituals.onnx\"\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "num_augmented_per_image = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d352f38-dee9-45f7-ad65-32db8ccb15bb",
   "metadata": {},
   "source": [
    "## 0.4 - Setup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffe97ec-1ee2-417b-b3bc-2e96cecb0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(filename):\n",
    "    img = Image.open(filename).convert('L')  # Conversion en niveaux de gris\n",
    "    img = img.resize((input_shape, input_shape))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    # Seuillage binaire\n",
    "    img = np.where(img > 127, 255.0, 0.0)\n",
    "    return img\n",
    "\n",
    "def load_images_from_directory(directory_path, max_images_per_label=None):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    label_names = []\n",
    "    \n",
    "    for label in os.listdir(directory_path):\n",
    "        label_path = os.path.join(directory_path, label)\n",
    "        # Ignorer les fichiers cachés comme .DS_Store\n",
    "        if label.startswith('.'):\n",
    "            continue\n",
    "\n",
    "        print(f\"Actually load : {label} with size : {len(os.listdir(label_path))}\")\n",
    "        if os.path.isdir(label_path):\n",
    "            label_image_count = 0\n",
    "            \n",
    "            for filename in os.listdir(label_path):\n",
    "                # Ignorer les fichiers cachés comme .DS_Store\n",
    "                if filename.startswith('.'):\n",
    "                    continue\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    if max_images_per_label is not None and label_image_count >= max_images_per_label:\n",
    "                        break\n",
    "                    image_paths.append(os.path.join(label_path, filename))\n",
    "                    labels.append(label)\n",
    "                    label_image_count += 1\n",
    "                    if label not in label_names:\n",
    "                        label_names.append(label)\n",
    "    \n",
    "    label_names.sort()\n",
    "    return image_paths, labels, label_names\n",
    "\n",
    "\n",
    "def images_to_numpy(image_paths, labels, label_names):\n",
    "    images = []\n",
    "    for path in tqdm(image_paths, desc=\"Processing images\", unit=\"image\"):\n",
    "        image = load_and_preprocess_image(path)\n",
    "        images.append(image)\n",
    "    \n",
    "    labels = [label_names.index(label) for label in labels]\n",
    "    \n",
    "    print(\"Converting images to NumPy array...\")\n",
    "    images = np.array(images)\n",
    "    return images, np.array(labels)\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = torch.FloatTensor(images).unsqueeze(1) / 255.0  # Normalisation [0, 1]\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "class RitualCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(RitualCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout3 = nn.Dropout2d(0.3)\n",
    "        \n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.dropout4 = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.relu(self.bn4(self.fc1(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "# Fonction de validation\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "def augment_image(img):\n",
    "    # Rotation aléatoire de -15 à +15 degrés\n",
    "    if random.random() < 0.5:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        img = img.rotate(angle)\n",
    "    \n",
    "    # Translation légère\n",
    "    if random.random() < 0.5:\n",
    "        max_shift = int(0.1 * input_shape)\n",
    "        x_shift = random.randint(-max_shift, max_shift)\n",
    "        y_shift = random.randint(-max_shift, max_shift)\n",
    "        img = ImageChops.offset(img, x_shift, y_shift)\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ade71-9d59-4b4e-bcbf-819ed6941f94",
   "metadata": {},
   "source": [
    "## 0.5 - Augment images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499d48c6-7d90-462a-bf0a-4059f9cc4924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete. Images saved in ./data_augment\n"
     ]
    }
   ],
   "source": [
    "for label in os.listdir(directory_path):\n",
    "    if label.startswith('.'):\n",
    "        continue\n",
    "    label_dir = os.path.join(directory_path, label)\n",
    "    if os.path.isdir(label_dir):\n",
    "        aug_label_dir = os.path.join(augmented_path, label)\n",
    "        os.makedirs(aug_label_dir, exist_ok=True)\n",
    "\n",
    "        for filename in os.listdir(label_dir):\n",
    "            if filename.startswith('.') or not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                continue\n",
    "            filepath = os.path.join(label_dir, filename)\n",
    "            try:\n",
    "                img = Image.open(filepath).convert('L')\n",
    "                img = img.resize((input_shape, input_shape))\n",
    "                \n",
    "                # Save original image to augmented folder\n",
    "                base_name, ext = os.path.splitext(filename)\n",
    "                img.save(os.path.join(aug_label_dir, f\"{base_name}_orig{ext}\"))\n",
    "                \n",
    "                # Generate augmented images\n",
    "                for i in range(num_augmented_per_image):\n",
    "                    aug_img = augment_image(img)\n",
    "                    aug_img.save(os.path.join(aug_label_dir, f\"{base_name}_aug{i+1}{ext}\"))\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filepath}: {e}\")\n",
    "\n",
    "print(f\"Augmentation complete. Images saved in {augmented_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb22f48-f722-42c1-b6ff-44d3207c6669",
   "metadata": {},
   "source": [
    "## 1.0 - Collect images and classify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba08751c-c223-4783-9182-70abced08bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actually load : pudor with size : 176\n",
      "Actually load : not_a with size : 265\n",
      "Actually load : mutus with size : 253\n",
      "Actually load : avarus with size : 165\n",
      "Actually load : flosculus with size : 276\n",
      "Actually load : acervus with size : 297\n",
      "Actually load : regium with size : 363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|████████████████████████████████████████████████████████████████████████| 1793/1793 [00:00<00:00, 7216.05image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting images to NumPy array...\n",
      "Total images: 1793\n",
      "Training images: 1147, Validation: 287, Test: 359\n",
      "Number of classes: 7\n",
      "Class names: ['acervus', 'avarus', 'flosculus', 'mutus', 'not_a', 'pudor', 'regium']\n"
     ]
    }
   ],
   "source": [
    "max_images_per_label = 1000000\n",
    "\n",
    "image_paths, labels, label_names = load_images_from_directory(\n",
    "    augmented_path, \n",
    "    max_images_per_label=max_images_per_label\n",
    ")\n",
    "images, labels = images_to_numpy(image_paths, labels, label_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = ImageDataset(X_train, y_train)\n",
    "test_dataset = ImageDataset(X_test, y_test)\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "num_classes = len(label_names)\n",
    "print(f\"Total images: {len(images)}\")\n",
    "print(f\"Training images: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {label_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23247e1-9645-4503-b333-288577aa392b",
   "metadata": {},
   "source": [
    "## 2.0 - Define model & function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb1db48-768d-4acb-a832-35ea39cfcc58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 128, 128]             320\n",
      "       BatchNorm2d-2         [-1, 32, 128, 128]              64\n",
      "              ReLU-3         [-1, 32, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 32, 64, 64]               0\n",
      "         Dropout2d-5           [-1, 32, 64, 64]               0\n",
      "            Conv2d-6           [-1, 64, 64, 64]          18,496\n",
      "       BatchNorm2d-7           [-1, 64, 64, 64]             128\n",
      "              ReLU-8           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-9           [-1, 64, 32, 32]               0\n",
      "        Dropout2d-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11          [-1, 128, 32, 32]          73,856\n",
      "      BatchNorm2d-12          [-1, 128, 32, 32]             256\n",
      "             ReLU-13          [-1, 128, 32, 32]               0\n",
      "        MaxPool2d-14          [-1, 128, 16, 16]               0\n",
      "        Dropout2d-15          [-1, 128, 16, 16]               0\n",
      "AdaptiveAvgPool2d-16            [-1, 128, 1, 1]               0\n",
      "           Linear-17                   [-1, 64]           8,256\n",
      "      BatchNorm1d-18                   [-1, 64]             128\n",
      "             ReLU-19                   [-1, 64]               0\n",
      "          Dropout-20                   [-1, 64]               0\n",
      "           Linear-21                    [-1, 7]             455\n",
      "================================================================\n",
      "Total params: 101,959\n",
      "Trainable params: 101,959\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 24.50\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 24.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = RitualCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-7\n",
    ")\n",
    "summary(model, input_size=(1, input_shape, input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d28e96-aff6-4957-8a69-7d433bbbebd0",
   "metadata": {},
   "source": [
    "## 2.1 - Training !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f532a524-c9d5-4bd5-a579-16e8b6934049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8473, Train Acc: 25.20%\n",
      "Val Loss: 1.8606, Val Acc: 24.39%\n",
      "Model saved!\n",
      "\n",
      "Epoch 2/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6470, Train Acc: 40.10%\n",
      "Val Loss: 1.4546, Val Acc: 52.26%\n",
      "Model saved!\n",
      "\n",
      "Epoch 3/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4762, Train Acc: 47.86%\n",
      "Val Loss: 1.2460, Val Acc: 62.37%\n",
      "Model saved!\n",
      "\n",
      "Epoch 4/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3376, Train Acc: 52.66%\n",
      "Val Loss: 1.1569, Val Acc: 60.28%\n",
      "Model saved!\n",
      "\n",
      "Epoch 5/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2050, Train Acc: 59.37%\n",
      "Val Loss: 0.9910, Val Acc: 68.29%\n",
      "Model saved!\n",
      "\n",
      "Epoch 6/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1457, Train Acc: 60.77%\n",
      "Val Loss: 0.9653, Val Acc: 66.20%\n",
      "Model saved!\n",
      "\n",
      "Epoch 7/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0323, Train Acc: 63.99%\n",
      "Val Loss: 0.8300, Val Acc: 73.52%\n",
      "Model saved!\n",
      "\n",
      "Epoch 8/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9849, Train Acc: 67.31%\n",
      "Val Loss: 0.7203, Val Acc: 74.56%\n",
      "Model saved!\n",
      "\n",
      "Epoch 9/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9006, Train Acc: 69.31%\n",
      "Val Loss: 0.6916, Val Acc: 74.56%\n",
      "Model saved!\n",
      "\n",
      "Epoch 10/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8231, Train Acc: 72.71%\n",
      "Val Loss: 0.5994, Val Acc: 80.14%\n",
      "Model saved!\n",
      "\n",
      "Epoch 11/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7925, Train Acc: 73.15%\n",
      "Val Loss: 0.5408, Val Acc: 84.67%\n",
      "Model saved!\n",
      "\n",
      "Epoch 12/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7110, Train Acc: 74.98%\n",
      "Val Loss: 0.5099, Val Acc: 82.93%\n",
      "Model saved!\n",
      "\n",
      "Epoch 13/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:54<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6753, Train Acc: 77.42%\n",
      "Val Loss: 0.4985, Val Acc: 80.84%\n",
      "Model saved!\n",
      "\n",
      "Epoch 14/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6403, Train Acc: 78.12%\n",
      "Val Loss: 0.4255, Val Acc: 84.67%\n",
      "Model saved!\n",
      "\n",
      "Epoch 15/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5981, Train Acc: 79.42%\n",
      "Val Loss: 0.4064, Val Acc: 83.62%\n",
      "Model saved!\n",
      "\n",
      "Epoch 16/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5874, Train Acc: 80.12%\n",
      "Val Loss: 0.3391, Val Acc: 89.55%\n",
      "Model saved!\n",
      "\n",
      "Epoch 17/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5693, Train Acc: 78.29%\n",
      "Val Loss: 0.3633, Val Acc: 85.37%\n",
      "\n",
      "Epoch 18/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5409, Train Acc: 81.60%\n",
      "Val Loss: 0.2998, Val Acc: 91.29%\n",
      "Model saved!\n",
      "\n",
      "Epoch 19/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4884, Train Acc: 83.52%\n",
      "Val Loss: 0.3093, Val Acc: 86.06%\n",
      "\n",
      "Epoch 20/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4756, Train Acc: 84.22%\n",
      "Val Loss: 0.2855, Val Acc: 90.24%\n",
      "Model saved!\n",
      "\n",
      "Epoch 21/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4588, Train Acc: 83.78%\n",
      "Val Loss: 0.2697, Val Acc: 91.99%\n",
      "Model saved!\n",
      "\n",
      "Epoch 22/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4318, Train Acc: 84.66%\n",
      "Val Loss: 0.3246, Val Acc: 85.37%\n",
      "\n",
      "Epoch 23/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3978, Train Acc: 87.18%\n",
      "Val Loss: 0.2102, Val Acc: 93.03%\n",
      "Model saved!\n",
      "\n",
      "Epoch 24/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3663, Train Acc: 87.88%\n",
      "Val Loss: 0.2212, Val Acc: 92.68%\n",
      "\n",
      "Epoch 25/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3670, Train Acc: 88.67%\n",
      "Val Loss: 0.2100, Val Acc: 93.38%\n",
      "Model saved!\n",
      "\n",
      "Epoch 26/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3449, Train Acc: 88.40%\n",
      "Val Loss: 0.1954, Val Acc: 94.43%\n",
      "Model saved!\n",
      "\n",
      "Epoch 27/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3638, Train Acc: 88.14%\n",
      "Val Loss: 0.2085, Val Acc: 92.68%\n",
      "\n",
      "Epoch 28/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3051, Train Acc: 89.97%\n",
      "Val Loss: 0.2054, Val Acc: 91.64%\n",
      "\n",
      "Epoch 29/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3223, Train Acc: 89.28%\n",
      "Val Loss: 0.1308, Val Acc: 98.61%\n",
      "Model saved!\n",
      "\n",
      "Epoch 30/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2777, Train Acc: 90.67%\n",
      "Val Loss: 0.1565, Val Acc: 97.21%\n",
      "\n",
      "Epoch 31/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2612, Train Acc: 91.72%\n",
      "Val Loss: 0.1919, Val Acc: 91.99%\n",
      "\n",
      "Epoch 32/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2757, Train Acc: 91.11%\n",
      "Val Loss: 0.1165, Val Acc: 98.26%\n",
      "Model saved!\n",
      "\n",
      "Epoch 33/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2988, Train Acc: 90.06%\n",
      "Val Loss: 0.1122, Val Acc: 98.26%\n",
      "Model saved!\n",
      "\n",
      "Epoch 34/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2653, Train Acc: 91.46%\n",
      "Val Loss: 0.1376, Val Acc: 96.17%\n",
      "\n",
      "Epoch 35/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2290, Train Acc: 91.98%\n",
      "Val Loss: 0.1627, Val Acc: 94.08%\n",
      "\n",
      "Epoch 36/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2298, Train Acc: 92.76%\n",
      "Val Loss: 0.0821, Val Acc: 98.26%\n",
      "Model saved!\n",
      "\n",
      "Epoch 37/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2215, Train Acc: 93.29%\n",
      "Val Loss: 0.0643, Val Acc: 98.61%\n",
      "Model saved!\n",
      "\n",
      "Epoch 38/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1913, Train Acc: 93.90%\n",
      "Val Loss: 0.0831, Val Acc: 98.61%\n",
      "\n",
      "Epoch 39/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1943, Train Acc: 93.03%\n",
      "Val Loss: 0.0638, Val Acc: 98.61%\n",
      "Model saved!\n",
      "\n",
      "Epoch 40/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2306, Train Acc: 92.24%\n",
      "Val Loss: 0.0766, Val Acc: 98.61%\n",
      "\n",
      "Epoch 41/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2026, Train Acc: 93.64%\n",
      "Val Loss: 0.0651, Val Acc: 98.61%\n",
      "\n",
      "Epoch 42/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1698, Train Acc: 94.25%\n",
      "Val Loss: 0.0615, Val Acc: 98.26%\n",
      "Model saved!\n",
      "\n",
      "Epoch 43/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1818, Train Acc: 94.07%\n",
      "Val Loss: 0.0712, Val Acc: 97.91%\n",
      "\n",
      "Epoch 44/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1851, Train Acc: 93.90%\n",
      "Val Loss: 0.0518, Val Acc: 99.30%\n",
      "Model saved!\n",
      "\n",
      "Epoch 45/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1862, Train Acc: 93.64%\n",
      "Val Loss: 0.0434, Val Acc: 99.65%\n",
      "Model saved!\n",
      "\n",
      "Epoch 46/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2039, Train Acc: 93.20%\n",
      "Val Loss: 0.0400, Val Acc: 99.30%\n",
      "Model saved!\n",
      "\n",
      "Epoch 47/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1776, Train Acc: 94.77%\n",
      "Val Loss: 0.0245, Val Acc: 99.65%\n",
      "Model saved!\n",
      "\n",
      "Epoch 48/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1417, Train Acc: 96.08%\n",
      "Val Loss: 0.0280, Val Acc: 99.65%\n",
      "\n",
      "Epoch 49/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:11<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1216, Train Acc: 96.60%\n",
      "Val Loss: 0.0487, Val Acc: 98.95%\n",
      "\n",
      "Epoch 50/50\n",
      "Current LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1367, Train Acc: 95.73%\n",
      "Val Loss: 0.0267, Val Acc: 99.65%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Current LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    if new_lr != old_lr:\n",
    "        print(f\"Learning rate reduced: {old_lr:.2e} -> {new_lr:.2e}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'rituals_pytorch.pth')\n",
    "        print(\"Model saved!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e10f75-ae95-4af6-b716-b9df8506cb80",
   "metadata": {},
   "source": [
    "## 2.2 - Save to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9e9a4-af8b-4d93-b146-46722134f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('rituals_pytorch.pth'))\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.randn(1, 1, input_shape, input_shape).to(device)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,                             \n",
    "    dummy_input,                       \n",
    "    'rituals_model.onnx',            \n",
    "    export_params=True,             \n",
    "    opset_version=11,                  \n",
    "    do_constant_folding=True,        \n",
    "    input_names=['input'],           \n",
    "    output_names=['output'],           \n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},    \n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Modèle exporté en ONNX : rituals_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c5bf12-5072-4ca2-8081-6563fc206f28",
   "metadata": {},
   "source": [
    "## 2.3 - Test with your new datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7c4aa-5b4f-47b1-b6e7-02ba5ccfc57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model.load_state_dict(torch.load('rituals_pytorch.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "def predict_image(image_path, model, device):\n",
    "    \"\"\"Prédit la classe d'une image\"\"\"\n",
    "    img = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    img_tensor = torch.FloatTensor(img).unsqueeze(0).unsqueeze(0) / 255.0\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    return predicted.item(), confidence.item(), probabilities[0].cpu().numpy()\n",
    "\n",
    "def test_on_folder(test_folder_path, model, label_names, device, num_images=16):\n",
    "    \"\"\"Teste le modèle sur un dossier et affiche les résultats\"\"\"\n",
    "    \n",
    "    all_images = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for label in os.listdir(test_folder_path):\n",
    "        label_path = os.path.join(test_folder_path, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for filename in os.listdir(label_path):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    all_images.append(os.path.join(label_path, filename))\n",
    "                    true_labels.append(label)\n",
    "    \n",
    "    indices = np.random.choice(len(all_images), min(num_images, len(all_images)), replace=False)\n",
    "    \n",
    "    rows = int(np.sqrt(num_images))\n",
    "    cols = int(np.ceil(num_images / rows))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for idx, img_idx in enumerate(indices):\n",
    "        image_path = all_images[img_idx]\n",
    "        true_label = true_labels[img_idx]\n",
    "        \n",
    "        pred_idx, confidence, probabilities = predict_image(image_path, model, device)\n",
    "        pred_label = label_names[pred_idx]\n",
    "        \n",
    "        img_display = Image.open(image_path).convert('L')\n",
    "        \n",
    "        is_correct = (pred_label == true_label)\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "        axes[idx].imshow(img_display, cmap='gray')\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        color = 'green' if is_correct else 'red'\n",
    "        title = f\"True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.2%}\"\n",
    "        axes[idx].set_title(title, fontsize=10, color=color, weight='bold')\n",
    "    \n",
    "    for idx in range(len(indices), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('test_predictions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"\\nAccuracy on sample: {accuracy:.2f}% ({correct}/{total})\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "test_folder_path = \"test\" \n",
    "accuracy = test_on_folder(test_folder_path, model, label_names, device, num_images=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd7043-2f3b-42ec-815e-4993f1e2b01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387dc682-7cce-43cc-9434-9ff8e066b207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
